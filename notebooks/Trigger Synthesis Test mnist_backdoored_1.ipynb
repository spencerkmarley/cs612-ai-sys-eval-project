{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2d93086",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNAME='mnist_backdoored_1' # 5 means class index 5 is backdoored\n",
    "MODELCLASS='MNIST'#'CIFAR10' 'MNIST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f27f704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import linalg as LA\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from torch import Tensor\n",
    "#from typing import Any\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import models.definitions.CIFAR100Net as CIFAR100\n",
    "import models.definitions.CIFAR10Net as CIFAR10\n",
    "import models.definitions.MNISTNet as MNIST\n",
    "\n",
    "# Class names for CIFAR10\n",
    "class_names_MNIST=['0','1','2','3','4','5','6','7','8','9']\n",
    "class_names_CIFAR10 = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
    "class_names_CIFAR100 =['beaver',\t'dolphin',\t'otter',\t'seal',\t'whale',\n",
    "'aquarium fish',\t'flatfish',\t'ray',\t'shark',\t'trout',\n",
    "'orchids',\t'poppies',\t'roses',\t'sunflowers',\t'tulips',\n",
    "'bottles',\t'bowls',\t'cans',\t'cups',\t'plates',\n",
    "'apples',\t'mushrooms',\t'oranges',\t'pears',\t'sweet peppers',\n",
    "'clock',\t'computer keyboard',\t'lamp',\t'telephone',\t'television',\n",
    "'bed',\t'chair',\t'couch',\t'table',\t'wardrobe',\n",
    "'bee',\t'beetle',\t'butterfly',\t'caterpillar',\t'cockroach',\n",
    "'bear',\t'leopard',\t'lion',\t'tiger',\t'wolf',\n",
    "'bridge',\t'castle',\t'house',\t'road',\t'skyscraper',\n",
    "'cloud',\t'forest',\t'mountain',\t'plain',\t'sea',\n",
    "'camel',\t'cattle',\t'chimpanzee',\t'elephant',\t'kangaroo',\n",
    "'fox',\t'porcupine',\t'possum',\t'raccoon',\t'skunk',\n",
    "'crab',\t'lobster',\t'snail',\t'spider',\t'worm',\n",
    "'baby',\t'boy',\t'girl',\t'man',\t'woman',\n",
    "'crocodile',\t'dinosaur',\t'lizard',\t'snake',\t'turtle',\n",
    "'hamster',\t'mouse',\t'rabbit',\t'shrew',\t'squirrel',\n",
    "'maple',\t'oak',\t'palm',\t'pine',\t'train',\n",
    "'bicycle',\t'bus',\t'motorcycle',\t'pickup truck',\t'truck',\n",
    "'lawn-mower',\t'rocket',\t'streetcar',\t'tank',\t'tractor']\n",
    "\n",
    "\n",
    "model_map={'CIFAR10':CIFAR10, 'CIFAR100':CIFAR100, 'MNIST':MNIST}\n",
    "triggersize_map={'CIFAR10':32, 'CIFAR100':32, 'MNIST':28}\n",
    "dim_map={'CIFAR10':3, 'CIFAR100':3, 'MNIST':1}\n",
    "trigger_type_map={'CIFAR10':[1,2], 'CIFAR100':[1,2], 'MNIST':[2]}\n",
    "class_names_map={'CIFAR10':class_names_CIFAR10, 'CIFAR100':class_names_CIFAR100, 'MNIST':class_names_MNIST}\n",
    "epochs_map={'CIFAR10':4 ,'CIFAR100':3, 'MNIST':2}\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90837d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining L norms\n",
    "\n",
    "def l1_norm(x: Tensor, y: Tensor=0) -> Tensor:\n",
    "    \"\"\" Compute the L1 norm between two tensors \"\"\"\n",
    "    res = torch.abs(x - y)\n",
    "    return torch.sum(res)\n",
    "\n",
    "def l2_norm(x, y=0):\n",
    "    \"\"\" Compute the L2 norm between two tensors \"\"\"\n",
    "    res = torch.sum((x - y) ** 2)\n",
    "    return torch.sqrt(res)\n",
    "\n",
    "def linf_norm(x, y=0):\n",
    "    \"\"\" Compute the L-inf norm between two tensors \"\"\"\n",
    "    res = torch.max(torch.abs(x - y))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff9fe056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, name):\n",
    "    torch.save(model.state_dict(), name)\n",
    "def load_model(model_class, name):\n",
    "    model = model_class()\n",
    "    model.load_state_dict(torch.load(name))\n",
    "\n",
    "    return model\n",
    "def generate_trigger(model, dataloader, delta_0,loss_fn, optimizer, device, bdtype):\n",
    "    #returns the trigger after this iteration\n",
    "    #delta_0 is the input trigger after last iteration\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    delta=delta_0.detach().clone().requires_grad_() #detach may not be needed\n",
    "    delta.retain_grad() #may not needed\n",
    "    #print(delta.is_leaf)\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        assert delta.requires_grad, \"Error: requires_grad is false\"\n",
    "        x_stamped=torch.add(x,delta) #from here delta is part of the graph\n",
    "        pred = model(x_stamped)\n",
    "        if bdtype=='MNIST':\n",
    "            loss = loss_fn(pred, y) + l1_norm(delta)+(delta<0).type(torch.float32).sum()\n",
    "        else:    \n",
    "            loss = loss_fn(pred, y) +l1_norm(delta[0,:,:])+l1_norm(delta[0,:,:]-delta[1,:,:])+l1_norm(delta[0,:,:]-delta[2,:,:])+l1_norm(delta[1,:,:]-delta[2,:,:])\n",
    "            #loss = loss_fn(pred, y) +LA.norm(LA.norm((torch.abs(delta)>0.01).type(torch.float32) ,2, dim=2),2)#+LA.norm(LA.norm((delta-0.5),1, dim=2),1)\n",
    "        \n",
    "        optimizer.zero_grad()         \n",
    "        loss.backward(inputs=delta)#(retain_graph=True)\n",
    "        #print(delta.grad.data.sum())\n",
    "        #optimizer.step()\n",
    "        temp = delta.detach().clone()\n",
    "        delta=(temp-(delta.grad*lr)).requires_grad_()\n",
    "        #delta.grad.data.zero_()\n",
    "        if batch % 100 == 0:\n",
    "            #print(w_Trigger.is_leaf,w_Trigger.grad.data.sum())\n",
    "            loss, current = loss.item(), batch * len(x)\n",
    "            print('loss: {:.4f} [{}/{}]'.format(loss, current, size))\n",
    "    return delta\n",
    "def test_trigger(model, dataloader,delta, loss_fn, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    loss, correct = 0.0, 0    \n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            x_stamped=torch.add(x,delta)\n",
    "            pred = model(x_stamped)\n",
    "            loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.int).sum().item()\n",
    "    \n",
    "    loss /= num_batches\n",
    "    correct /= size\n",
    "    print('Test Result: Accuracy @ {:.2f}%, Avg loss @ {:.4f}\\n'.format(100 * correct, loss))\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aab5025",
   "metadata": {},
   "source": [
    "## number of epochs have been fine tuned for CIFAR 10 and 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5748f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TriggerSize=triggersize_map[MODELCLASS]\n",
    "testmodel=load_model(model_map[MODELCLASS],  f'../model/{MODELNAME}.pt')\n",
    "testmodel=testmodel.to(device)\n",
    "transform = transforms.ToTensor()\n",
    "train_kwargs = {'batch_size': 100, 'shuffle':True}\n",
    "test_kwargs = {'batch_size': 1000}\n",
    "lr=0.01\n",
    "optimizer = optim.Adam(testmodel.parameters(), lr=0.1) # not using optimizer here\n",
    "num_of_epochs = epochs_map[MODELCLASS]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fd0f24",
   "metadata": {},
   "source": [
    "\n",
    "running trigger generation for the first 10 classes only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5647f83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# to map dataset, add this block if need to re-download a fresh dataset\n",
    "trainset_map={'CIFAR10':torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform),\n",
    "              'CIFAR100':torchvision.datasets.CIFAR100(root='./data', train=True,download=True, transform=transform),\n",
    "              'MNIST':torchvision.datasets.MNIST(root='./data', train=True,download=True, transform=transform)}\n",
    "testset_map={'CIFAR10':torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform),\n",
    "              'CIFAR100':torchvision.datasets.CIFAR100(root='./data', train=False,download=True, transform=transform),\n",
    "              'MNIST':torchvision.datasets.MNIST(root='./data', train=False,download=True, transform=transform)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aca6987",
   "metadata": {},
   "source": [
    "#### Set to run for the first 10 classes only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90478019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With target number 0:\n",
      "loss: 405.5315 [0/60000]\n",
      "loss: 416.6875 [10000/60000]\n",
      "loss: 376.6722 [20000/60000]\n",
      "loss: 411.6580 [30000/60000]\n",
      "loss: 409.5657 [40000/60000]\n",
      "loss: 402.7751 [50000/60000]\n",
      "Test Result: Accuracy @ 10.17%, Avg loss @ 10.9404\n",
      "\n",
      "With target number 0:\n",
      "loss: 422.9821 [0/60000]\n",
      "loss: 402.2045 [10000/60000]\n",
      "loss: 392.3390 [20000/60000]\n",
      "loss: 392.9759 [30000/60000]\n",
      "loss: 387.4832 [40000/60000]\n",
      "loss: 437.1230 [50000/60000]\n",
      "Test Result: Accuracy @ 10.13%, Avg loss @ 11.0795\n",
      "\n",
      "With target number 1:\n",
      "loss: 416.2629 [0/60000]\n",
      "loss: 396.1536 [10000/60000]\n",
      "loss: 391.0537 [20000/60000]\n",
      "loss: 395.2506 [30000/60000]\n",
      "loss: 439.9431 [40000/60000]\n",
      "loss: 398.3622 [50000/60000]\n",
      "Test Result: Accuracy @ 11.30%, Avg loss @ 14.1806\n",
      "\n",
      "With target number 1:\n",
      "loss: 409.3044 [0/60000]\n",
      "loss: 410.8824 [10000/60000]\n",
      "loss: 401.3192 [20000/60000]\n",
      "loss: 416.3755 [30000/60000]\n",
      "loss: 432.0735 [40000/60000]\n",
      "loss: 432.8119 [50000/60000]\n",
      "Test Result: Accuracy @ 11.37%, Avg loss @ 14.1301\n",
      "\n",
      "With target number 2:\n",
      "loss: 402.1357 [0/60000]\n",
      "loss: 412.4901 [10000/60000]\n",
      "loss: 400.1497 [20000/60000]\n",
      "loss: 415.6615 [30000/60000]\n",
      "loss: 423.5729 [40000/60000]\n",
      "loss: 397.1225 [50000/60000]\n",
      "Test Result: Accuracy @ 12.57%, Avg loss @ 7.8091\n",
      "\n",
      "With target number 2:\n",
      "loss: 395.6390 [0/60000]\n",
      "loss: 393.5187 [10000/60000]\n",
      "loss: 410.0086 [20000/60000]\n",
      "loss: 401.4619 [30000/60000]\n",
      "loss: 409.4703 [40000/60000]\n",
      "loss: 396.8502 [50000/60000]\n",
      "Test Result: Accuracy @ 13.18%, Avg loss @ 7.6615\n",
      "\n",
      "With target number 3:\n",
      "loss: 395.6087 [0/60000]\n",
      "loss: 397.9735 [10000/60000]\n",
      "loss: 360.4951 [20000/60000]\n",
      "loss: 402.0620 [30000/60000]\n",
      "loss: 372.6967 [40000/60000]\n",
      "loss: 389.3288 [50000/60000]\n",
      "Test Result: Accuracy @ 12.38%, Avg loss @ 7.7343\n",
      "\n",
      "With target number 3:\n",
      "loss: 412.5042 [0/60000]\n",
      "loss: 390.1033 [10000/60000]\n",
      "loss: 403.8975 [20000/60000]\n",
      "loss: 390.6122 [30000/60000]\n",
      "loss: 391.6875 [40000/60000]\n",
      "loss: 395.7907 [50000/60000]\n",
      "Test Result: Accuracy @ 12.44%, Avg loss @ 7.6851\n",
      "\n",
      "With target number 4:\n",
      "loss: 421.1245 [0/60000]\n",
      "loss: 418.9169 [10000/60000]\n",
      "loss: 403.6747 [20000/60000]\n",
      "loss: 420.3371 [30000/60000]\n",
      "loss: 421.6791 [40000/60000]\n",
      "loss: 419.0048 [50000/60000]\n",
      "Test Result: Accuracy @ 10.23%, Avg loss @ 11.3554\n",
      "\n",
      "With target number 4:\n",
      "loss: 429.1584 [0/60000]\n",
      "loss: 440.1976 [10000/60000]\n",
      "loss: 434.8344 [20000/60000]\n",
      "loss: 418.9471 [30000/60000]\n",
      "loss: 432.8085 [40000/60000]\n",
      "loss: 446.7028 [50000/60000]\n",
      "Test Result: Accuracy @ 10.21%, Avg loss @ 11.3917\n",
      "\n",
      "With target number 5:\n",
      "loss: 398.1135 [0/60000]\n",
      "loss: 392.3148 [10000/60000]\n",
      "loss: 400.4595 [20000/60000]\n",
      "loss: 419.8704 [30000/60000]\n",
      "loss: 389.7747 [40000/60000]\n",
      "loss: 409.0265 [50000/60000]\n",
      "Test Result: Accuracy @ 9.14%, Avg loss @ 8.5346\n",
      "\n",
      "With target number 5:\n",
      "loss: 409.9503 [0/60000]\n",
      "loss: 404.0567 [10000/60000]\n",
      "loss: 416.5134 [20000/60000]\n",
      "loss: 400.6242 [30000/60000]\n",
      "loss: 388.4848 [40000/60000]\n",
      "loss: 393.5428 [50000/60000]\n",
      "Test Result: Accuracy @ 9.18%, Avg loss @ 8.5254\n",
      "\n",
      "With target number 6:\n",
      "loss: 425.9048 [0/60000]\n",
      "loss: 407.2040 [10000/60000]\n",
      "loss: 421.0650 [20000/60000]\n",
      "loss: 435.1166 [30000/60000]\n",
      "loss: 419.7660 [40000/60000]\n",
      "loss: 431.8666 [50000/60000]\n",
      "Test Result: Accuracy @ 11.04%, Avg loss @ 10.8323\n",
      "\n",
      "With target number 6:\n",
      "loss: 457.1140 [0/60000]\n",
      "loss: 406.0785 [10000/60000]\n",
      "loss: 440.0476 [20000/60000]\n",
      "loss: 421.3130 [30000/60000]\n",
      "loss: 426.6108 [40000/60000]\n",
      "loss: 418.9602 [50000/60000]\n",
      "Test Result: Accuracy @ 11.36%, Avg loss @ 10.2754\n",
      "\n",
      "With target number 7:\n",
      "loss: 402.8066 [0/60000]\n",
      "loss: 413.7978 [10000/60000]\n",
      "loss: 398.5932 [20000/60000]\n",
      "loss: 378.0914 [30000/60000]\n",
      "loss: 400.3172 [40000/60000]\n",
      "loss: 396.9598 [50000/60000]\n",
      "Test Result: Accuracy @ 78.94%, Avg loss @ 0.9528\n",
      "\n",
      "With target number 7:\n",
      "loss: 410.8510 [0/60000]\n",
      "loss: 404.8887 [10000/60000]\n",
      "loss: 392.5110 [20000/60000]\n",
      "loss: 427.5708 [30000/60000]\n",
      "loss: 419.3147 [40000/60000]\n",
      "loss: 370.4091 [50000/60000]\n",
      "Test Result: Accuracy @ 77.80%, Avg loss @ 1.0071\n",
      "\n",
      "With target number 8:\n",
      "loss: 403.0419 [0/60000]\n",
      "loss: 412.8509 [10000/60000]\n",
      "loss: 386.1976 [20000/60000]\n",
      "loss: 406.2790 [30000/60000]\n",
      "loss: 411.2912 [40000/60000]\n",
      "loss: 404.2816 [50000/60000]\n",
      "Test Result: Accuracy @ 37.48%, Avg loss @ 3.0558\n",
      "\n",
      "With target number 8:\n",
      "loss: 417.0739 [0/60000]\n",
      "loss: 376.3566 [10000/60000]\n",
      "loss: 408.9370 [20000/60000]\n",
      "loss: 413.3231 [30000/60000]\n",
      "loss: 387.0100 [40000/60000]\n",
      "loss: 400.9005 [50000/60000]\n",
      "Test Result: Accuracy @ 39.13%, Avg loss @ 2.9319\n",
      "\n",
      "With target number 9:\n",
      "loss: 402.9572 [0/60000]\n",
      "loss: 386.6288 [10000/60000]\n",
      "loss: 422.4203 [20000/60000]\n",
      "loss: 407.5356 [30000/60000]\n",
      "loss: 398.7672 [40000/60000]\n",
      "loss: 431.8547 [50000/60000]\n",
      "Test Result: Accuracy @ 18.06%, Avg loss @ 6.4937\n",
      "\n",
      "With target number 9:\n",
      "loss: 419.1253 [0/60000]\n",
      "loss: 392.4416 [10000/60000]\n",
      "loss: 407.0386 [20000/60000]\n",
      "loss: 401.8561 [30000/60000]\n",
      "loss: 396.9578 [40000/60000]\n",
      "loss: 401.7493 [50000/60000]\n",
      "Test Result: Accuracy @ 18.12%, Avg loss @ 6.5285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CLASSES=[i for i in range(10)]  # change to selected classes for CIFAR100 !!!\n",
    "\n",
    "triggers1={}\n",
    "acc1={}\n",
    "for TARGET in CLASSES:\n",
    "    delta =torch.zeros([dim_map[MODELCLASS],TriggerSize,TriggerSize], requires_grad=True, device=device)+0.5\n",
    "    trainset = trainset_map[MODELCLASS]\n",
    "    testset = testset_map[MODELCLASS]\n",
    "\n",
    "    for i in range(len(trainset)):\n",
    "        trainset.targets[i]=TARGET  \n",
    "    for i in range(len(testset)):\n",
    "        testset.targets[i]=TARGET  \n",
    "    \n",
    "    trigger_gen_loader = DataLoader(trainset, **train_kwargs)\n",
    "    trigger_test_loader = DataLoader(testset, **test_kwargs)\n",
    "    \n",
    "    for epoch in range(num_of_epochs):\n",
    "        print(f'With target number {TARGET}:' )\n",
    "        delta=generate_trigger(testmodel, trigger_gen_loader, delta , nn.CrossEntropyLoss(), optimizer, device, bdtype=MODELCLASS)\n",
    "        test_acc=test_trigger(testmodel, trigger_test_loader,delta, nn.CrossEntropyLoss(), device)\n",
    "    triggers1[TARGET]=delta\n",
    "    acc1[TARGET]=test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82c2d85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4.00      4.46      5.25      4.87      3.98      4.07      7.19      7.76      6.60      6.01\n",
      "      0.17      0.26      1.09      0.77      0.17      0.17      1.89      1.62      1.16      1.05\n",
      "      0.02      0.14      1.06      0.75      0.01      0.01      1.50      0.80      0.76      0.67\n",
      "      0      3      2      1      0      0      3      6      6      4\n",
      "    0.1013    0.1137    0.1318    0.1244    0.1021    0.0918    0.1136    0.7780    0.3913    0.1812\n",
      "Infected Classes:\n",
      "[]\n",
      "[7]\n"
     ]
    }
   ],
   "source": [
    "print(  \"\".join(\"{:10.2f}\".format(l1_norm(triggers1[i]).item()) for i in range(10))  )\n",
    "print(  \"\".join(\"{:10.2f}\".format(l2_norm(triggers1[i]).item()) for i in range(10))  )\n",
    "print(  \"\".join(\"{:10.2f}\".format(linf_norm(triggers1[i]).item()) for i in range(10))  )\n",
    "print(\"      \"+\"      \".join([str((abs(triggers1[i])>0.05).sum().item()) for i in range(10)]))\n",
    "print(\"\".join([\"{:10.4f}\".format(value) for key,value in acc1.items()]))\n",
    "\n",
    "def MAD_anomaly_index(X): #X is a list of numbers (L1, L2 etc)\n",
    "    Xm = np.median(X)\n",
    "    devs = X-Xm\n",
    "    abs_devs=abs(devs)\n",
    "    MAD = np.median(abs_devs)\n",
    "    degree_of_anomaly = devs/MAD #<-2\n",
    "    return degree_of_anomaly,(degree_of_anomaly<-2).sum()\n",
    "\n",
    "L=[l1_norm(triggers1[i]).item() for i in range(10)]\n",
    "L1=MAD_anomaly_index([l1_norm(triggers1[i]).item() for i in range(10)])[0]<-2\n",
    "Linf=MAD_anomaly_index([linf_norm(triggers1[i]).item() for i in range(10)])[0]<-2\n",
    "L_acc=MAD_anomaly_index([value for key,value in acc1.items()])[0]>2\n",
    "print(\"Infected Classes:\")\n",
    "print([i for i in range(10) if L1[i]])\n",
    "print([i for i in range(10) if (L_acc[i] and acc1[i]>0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed2e70d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
